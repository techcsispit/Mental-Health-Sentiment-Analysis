{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:7px; color:white; margin:0; font-size:150%; font-family:Arial; background-color:#C0DDD1; color: #1D3037; overflow:hidden\"><b> Sentiment Analysis for Mental Health </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mentalhealth](https://img.freepik.com/free-vector/anxiety-concept-illustration_114360-8074.jpg?t=st=1724423293~exp=1724426893~hmac=df2c665ea2a184797d9d3bac091a98ebb6d360a4827e62d62be92a4f04edfd5b&w=1380)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mental health is a critical aspect of overall well-being, and understanding the nuances of mental health conditions can be a powerful tool in providing timely support and interventions. In this project, we perform sentiment analysis on textual data to predict the mental health status of individuals based on their statements. By analyzing the language used in these statements, we aim to accurately classify them into one of seven mental health categories: Normal, Depression, Suicidal, Anxiety, Stress, Bi-Polar, and Personality Disorder.\n",
    "\n",
    "By applying advanced natural language processing (NLP) techniques and machine learning models, we seek to classify these statements accurately. The insights from this analysis could help mental health professionals in early identification and intervention. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:06.469676Z",
     "iopub.status.busy": "2024-08-29T16:50:06.468938Z",
     "iopub.status.idle": "2024-08-29T16:50:06.484387Z",
     "shell.execute_reply": "2024-08-29T16:50:06.48336Z",
     "shell.execute_reply.started": "2024-08-29T16:50:06.469631Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('''\n",
    "<div style=\"display: flex; justify-content: space-between; align-items: center; width: 300px; margin: 0 auto;\">\n",
    "    <!-- Left Circle Image -->\n",
    "    <div style=\"width: 120px; height: 120px; overflow: hidden; border-radius: 50%; display: inline-block;\">\n",
    "        <img src=\"https://i.postimg.cc/Sx3LT77N/2023-06-02-11-25-26-286-0500-2.jpg\" alt=\"Left Image\" style=\"width: 100%; height: 100%; object-fit: cover;\">\n",
    "    </div>\n",
    "    \n",
    "    <!-- Right Circle Image -->\n",
    "    <div style=\"width: 120px; height: 120px; overflow: hidden; border-radius: 50%; display: inline-block;\">\n",
    "        <img src=\"https://i.postimg.cc/fbJY8vKH/IMG-20240826-WA0007.jpg\" alt=\"Right Image\" style=\"width: 100%; height: 100%; object-fit: cover;\">\n",
    "    </div>\n",
    "</div>\n",
    "'''))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"libraries\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:9px; color:white; margin:0; font-size:110%; font-family:Arial; background-color:#419D78; overflow:hidden\"><b> 1. Importing Required Libraries </b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:06.486486Z",
     "iopub.status.busy": "2024-08-29T16:50:06.486083Z",
     "iopub.status.idle": "2024-08-29T16:50:09.681404Z",
     "shell.execute_reply": "2024-08-29T16:50:09.68025Z",
     "shell.execute_reply.started": "2024-08-29T16:50:06.486443Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import random\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.sparse import hstack  # To combine sparse matrices\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:9px; color:white; margin:0; font-size:110%; font-family:Arial; background-color:#419D78; overflow:hidden\"><b> 2. Reading and Understanding our Data </b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:09.684077Z",
     "iopub.status.busy": "2024-08-29T16:50:09.683208Z",
     "iopub.status.idle": "2024-08-29T16:50:10.677355Z",
     "shell.execute_reply": "2024-08-29T16:50:10.67625Z",
     "shell.execute_reply.started": "2024-08-29T16:50:09.684036Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/kaggle/input/sentiment-analysis-for-mental-health/Combined Data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:10.679163Z",
     "iopub.status.busy": "2024-08-29T16:50:10.678724Z",
     "iopub.status.idle": "2024-08-29T16:50:10.696183Z",
     "shell.execute_reply": "2024-08-29T16:50:10.695048Z",
     "shell.execute_reply.started": "2024-08-29T16:50:10.679116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:10.699589Z",
     "iopub.status.busy": "2024-08-29T16:50:10.69914Z",
     "iopub.status.idle": "2024-08-29T16:50:10.81131Z",
     "shell.execute_reply": "2024-08-29T16:50:10.810219Z",
     "shell.execute_reply.started": "2024-08-29T16:50:10.699538Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:10.813347Z",
     "iopub.status.busy": "2024-08-29T16:50:10.812866Z",
     "iopub.status.idle": "2024-08-29T16:50:10.843087Z",
     "shell.execute_reply": "2024-08-29T16:50:10.841645Z",
     "shell.execute_reply.started": "2024-08-29T16:50:10.813289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:10.845536Z",
     "iopub.status.busy": "2024-08-29T16:50:10.84497Z",
     "iopub.status.idle": "2024-08-29T16:50:10.869086Z",
     "shell.execute_reply": "2024-08-29T16:50:10.867891Z",
     "shell.execute_reply.started": "2024-08-29T16:50:10.845468Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:10.871305Z",
     "iopub.status.busy": "2024-08-29T16:50:10.870805Z",
     "iopub.status.idle": "2024-08-29T16:50:10.91036Z",
     "shell.execute_reply": "2024-08-29T16:50:10.909341Z",
     "shell.execute_reply.started": "2024-08-29T16:50:10.87122Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:10.912294Z",
     "iopub.status.busy": "2024-08-29T16:50:10.911921Z",
     "iopub.status.idle": "2024-08-29T16:50:10.928191Z",
     "shell.execute_reply": "2024-08-29T16:50:10.927002Z",
     "shell.execute_reply.started": "2024-08-29T16:50:10.912254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:10.930553Z",
     "iopub.status.busy": "2024-08-29T16:50:10.930119Z",
     "iopub.status.idle": "2024-08-29T16:50:11.392647Z",
     "shell.execute_reply": "2024-08-29T16:50:11.391475Z",
     "shell.execute_reply.started": "2024-08-29T16:50:10.930497Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Count the occurrences of each category\n",
    "status_counts = df['status'].value_counts()\n",
    "\n",
    "# Define colors for each category (7 colors)\n",
    "colors = ['#419D78', '#E0A458', '#2D3047', '#FFDBB5', '#C04ABC', '#B3CDE0', '#D0D0D0']\n",
    "\n",
    "# Create the pie chart\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.pie(status_counts, labels=status_counts.index, autopct='%1.1f%%', \n",
    "        startangle=140, colors=colors, shadow=True)\n",
    "\n",
    "plt.title('Distribution of Mental Health Conditions')\n",
    "plt.axis('equal')  # Equal aspect ratio ensures that the pie is drawn as a circle.\n",
    "\n",
    "# Display the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 20px; border-color: #419D78; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #419D78;\">\n",
    "    <ul style=\"font-size: 18px; font-family: 'Arial'; line-height: 1.5em; \">\n",
    "        The target variable in our dataset is <strong>unbalanced</strong>. This imbalance could affect our model's performance, so we'll need to address it later to ensure accurate and fair predictions.\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at raw texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:11.397671Z",
     "iopub.status.busy": "2024-08-29T16:50:11.396852Z",
     "iopub.status.idle": "2024-08-29T16:50:11.422492Z",
     "shell.execute_reply": "2024-08-29T16:50:11.421434Z",
     "shell.execute_reply.started": "2024-08-29T16:50:11.397624Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Group by status and get a random statement from each group\n",
    "random_statements = df.groupby('status')['statement'].apply(lambda x: x.sample(n=1).iloc[0])\n",
    "\n",
    "# Print the results\n",
    "for status, statement in random_statements.items():\n",
    "    print(f\"Status: {status}\")\n",
    "    print(f\"Statement: {statement}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:11.423988Z",
     "iopub.status.busy": "2024-08-29T16:50:11.423659Z",
     "iopub.status.idle": "2024-08-29T16:50:37.587301Z",
     "shell.execute_reply": "2024-08-29T16:50:37.586196Z",
     "shell.execute_reply.started": "2024-08-29T16:50:11.423949Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculate the number of characters and sentences\n",
    "df['num_of_characters'] = df['statement'].str.len()\n",
    "df['num_of_sentences'] = df['statement'].apply(lambda x: len(nltk.sent_tokenize(x)))\n",
    "\n",
    "# Generate descriptive statistics\n",
    "description = df[['num_of_characters', 'num_of_sentences']].describe()\n",
    "\n",
    "# Display the descriptive statistics\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 20px; border-color: #419D78; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #419D78;\">\n",
    "    <ul style=\"font-size: 18px; font-family: 'Arial'; line-height: 1.5em; \">\n",
    "        We have several lengthy messages, most of which express suicidal thoughts or signs of depression:\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:37.588987Z",
     "iopub.status.busy": "2024-08-29T16:50:37.588652Z",
     "iopub.status.idle": "2024-08-29T16:50:37.604832Z",
     "shell.execute_reply": "2024-08-29T16:50:37.603676Z",
     "shell.execute_reply.started": "2024-08-29T16:50:37.588952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[df['num_of_characters'] > 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"preprocessing\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:9px; color:white; margin:0; font-size:110%; font-family:Arial; background-color:#419D78; overflow:hidden\"><b> 3. Text Preprocessing </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Lowercasing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all statements to lowercase to ensure uniformity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:37.606539Z",
     "iopub.status.busy": "2024-08-29T16:50:37.606186Z",
     "iopub.status.idle": "2024-08-29T16:50:37.730778Z",
     "shell.execute_reply": "2024-08-29T16:50:37.729856Z",
     "shell.execute_reply.started": "2024-08-29T16:50:37.606482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.rename(columns={'statement': 'original_statement'}, inplace=True)  \n",
    "\n",
    "df['statement']=df['original_statement'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Removing URLs, handles, punctuation and special characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove specific patterns such as URLs or other unwanted text (like ```[View Poll](https://www.reddit.com/poll/...)```) from a column in a pandas DataFrame, we can use regular expressions with the re module or pandas built-in string methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:37.732405Z",
     "iopub.status.busy": "2024-08-29T16:50:37.732075Z",
     "iopub.status.idle": "2024-08-29T16:50:39.362974Z",
     "shell.execute_reply": "2024-08-29T16:50:39.361832Z",
     "shell.execute_reply.started": "2024-08-29T16:50:37.732369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_patterns(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://\\S+', '', text)\n",
    "    # Remove markdown-style links\n",
    "    text = re.sub(r'\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    # Remove handles (that start with '@')\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove punctuation and other special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Apply the function to the 'statement' column\n",
    "df['statement'] = df['statement'].apply(remove_patterns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split text into individual words or tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:50:39.364654Z",
     "iopub.status.busy": "2024-08-29T16:50:39.364224Z",
     "iopub.status.idle": "2024-08-29T16:51:37.338988Z",
     "shell.execute_reply": "2024-08-29T16:51:37.33786Z",
     "shell.execute_reply.started": "2024-08-29T16:50:39.364608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply word_tokenize to each element in the 'statement' column\n",
    "df['tokens'] = df['statement'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduce words to their base or root form. However, in some cases, the stemming process produces words that are not correct spellings of the root word. For example, **happi** and **sunni**. That's because it chooses the most common stem for related words. For example, we can look at the set of words that comprises the different forms of happy:\n",
    "\n",
    "- happy\n",
    "- happiness\n",
    "- happier\n",
    "\n",
    "We can see that the prefix **happi** is more commonly used. We cannot choose **happ** because it is the stem of unrelated words like **happen**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:51:37.340399Z",
     "iopub.status.busy": "2024-08-29T16:51:37.340079Z",
     "iopub.status.idle": "2024-08-29T16:54:15.632627Z",
     "shell.execute_reply": "2024-08-29T16:54:15.631547Z",
     "shell.execute_reply.started": "2024-08-29T16:51:37.340364Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize the stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function to stem tokens and convert them to strings\n",
    "def stem_tokens(tokens):\n",
    "    return ' '.join(stemmer.stem(str(token)) for token in tokens)\n",
    "\n",
    "# Apply the function to the 'tokens' column\n",
    "df['tokens_stemmed'] = df['tokens'].apply(stem_tokens)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While stop words are typically removed to reduce noise, in sentiment analysis for mental health, many stop words are actually crucial for understanding context and sentiment. Words like negations and those related to emotions (e.g., 'how', 'why', 'because') provide important insights. Removing these can decrease the accuracy of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3.6. Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:54:15.634207Z",
     "iopub.status.busy": "2024-08-29T16:54:15.633861Z",
     "iopub.status.idle": "2024-08-29T16:54:46.393144Z",
     "shell.execute_reply": "2024-08-29T16:54:46.392116Z",
     "shell.execute_reply.started": "2024-08-29T16:54:15.634172Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get unique categories in 'status'\n",
    "statuses = df['status'].unique()\n",
    "\n",
    "# Define a color function\n",
    "def color_func(word, font_size, position, orientation, random_state=101, **kwargs):\n",
    "    return random.choice(colors)\n",
    "\n",
    "# Generate and plot the WordCloud for each category\n",
    "for status in statuses:\n",
    "    # Filter the tokens data for the current status\n",
    "    tokens_data = ' '.join(df[df['status'] == status]['tokens'].dropna().apply(lambda x: ' '.join(x)).tolist())\n",
    "\n",
    "    # Generate the WordCloud\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', color_func=color_func).generate(tokens_data)\n",
    "    \n",
    "    # Plot the WordCloud\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')  # Turn off axis\n",
    "    plt.title(f'WordCloud for Status: {status}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 20px; border-color: #419D78; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #419D78;\">\n",
    "    <ul style=\"font-size: 18px; font-family: 'Arial'; line-height: 1.5em; \">\n",
    "        There is a significant overlap in the language used for discussing depression and suicidal thoughts in our data. Many terms and phrases are used interchangeably or similarly for both conditions, which may complicate the distinction between them. \n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datapreprocessing\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:9px; color:white; margin:0; font-size:110%; font-family:Arial; background-color:#419D78; overflow:hidden\"><b> 4. Data Preprocessing </b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Separate features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:54:46.394857Z",
     "iopub.status.busy": "2024-08-29T16:54:46.394493Z",
     "iopub.status.idle": "2024-08-29T16:54:46.402891Z",
     "shell.execute_reply": "2024-08-29T16:54:46.401819Z",
     "shell.execute_reply.started": "2024-08-29T16:54:46.394819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X = df[['tokens_stemmed', 'num_of_characters', 'num_of_sentences']]\n",
    "y = df['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Label encoding target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:54:46.4045Z",
     "iopub.status.busy": "2024-08-29T16:54:46.404115Z",
     "iopub.status.idle": "2024-08-29T16:54:46.426488Z",
     "shell.execute_reply": "2024-08-29T16:54:46.425262Z",
     "shell.execute_reply.started": "2024-08-29T16:54:46.404461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lbl_enc = LabelEncoder()\n",
    "y = lbl_enc.fit_transform(y.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:54:46.42845Z",
     "iopub.status.busy": "2024-08-29T16:54:46.427924Z",
     "iopub.status.idle": "2024-08-29T16:54:46.443924Z",
     "shell.execute_reply": "2024-08-29T16:54:46.442932Z",
     "shell.execute_reply.started": "2024-08-29T16:54:46.428404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Convert text to features using TF-IDF vectoriser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will transform tokens (words) into numerical values that represent the importance of words in a document relative to a collection of documents. This helps highlight unique words in a document while downplaying common ones, making it easier for machine learning models to identify relevant patterns and make better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:54:46.445534Z",
     "iopub.status.busy": "2024-08-29T16:54:46.445162Z",
     "iopub.status.idle": "2024-08-29T16:55:03.368491Z",
     "shell.execute_reply": "2024-08-29T16:55:03.367456Z",
     "shell.execute_reply.started": "2024-08-29T16:54:46.445493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# 1. Initialize TF-IDF Vectorizer and fit/transform on the 'tokens' column\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=50000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train['tokens_stemmed'])\n",
    "X_test_tfidf = vectorizer.transform(X_test['tokens_stemmed'])\n",
    "\n",
    "# 2. Extract numerical features\n",
    "X_train_num = X_train[['num_of_characters', 'num_of_sentences']].values\n",
    "X_test_num = X_test[['num_of_characters', 'num_of_sentences']].values\n",
    "\n",
    "# 3. Combine TF-IDF features with numerical features\n",
    "X_train_combined = hstack([X_train_tfidf, X_train_num])\n",
    "X_test_combined = hstack([X_test_tfidf, X_test_num])\n",
    "\n",
    "print('Number of feature words: ', len(vectorizer.get_feature_names_out()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:55:03.370541Z",
     "iopub.status.busy": "2024-08-29T16:55:03.370034Z",
     "iopub.status.idle": "2024-08-29T16:55:03.376867Z",
     "shell.execute_reply": "2024-08-29T16:55:03.375959Z",
     "shell.execute_reply.started": "2024-08-29T16:55:03.370489Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We experimented with various resampling techniques, including SMOTE, Random Over-Sampling and Random Under-Sampling. Among these, Random Over-Sampling provided the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:55:03.379271Z",
     "iopub.status.busy": "2024-08-29T16:55:03.378496Z",
     "iopub.status.idle": "2024-08-29T16:55:03.814968Z",
     "shell.execute_reply": "2024-08-29T16:55:03.813996Z",
     "shell.execute_reply.started": "2024-08-29T16:55:03.379235Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Apply Random Over-Sampling on the vectorized data\n",
    "ros = RandomOverSampler(random_state=101)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train_combined, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:55:03.816585Z",
     "iopub.status.busy": "2024-08-29T16:55:03.816229Z",
     "iopub.status.idle": "2024-08-29T16:55:03.823394Z",
     "shell.execute_reply": "2024-08-29T16:55:03.822219Z",
     "shell.execute_reply.started": "2024-08-29T16:55:03.816546Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train_resampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n",
    "# <div style=\"text-align:center; border-radius:30px 30px; padding:9px; color:white; margin:0; font-size:110%; font-family:Arial; background-color:#419D78; overflow:hidden\"><b> 5. Model Traning and Evaluation </b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:55:03.825008Z",
     "iopub.status.busy": "2024-08-29T16:55:03.824654Z",
     "iopub.status.idle": "2024-08-29T16:55:03.833755Z",
     "shell.execute_reply": "2024-08-29T16:55:03.832672Z",
     "shell.execute_reply.started": "2024-08-29T16:55:03.824972Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define a dictionary of classifiers with their specific parameters.\n",
    "# Note: The hyperparameters for these classifiers were chosen after performing GridSearchCV to optimize performance.\n",
    "classifiers = {\n",
    "    'Bernoulli Naive Bayes': BernoulliNB(alpha=0.1, binarize=0.0),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=9, min_samples_split=5, random_state=101), \n",
    "    'Logistic Regression': LogisticRegression(solver='liblinear', penalty='l1', C=10, random_state=101),\n",
    "    'XGB': XGBClassifier(learning_rate=0.2, max_depth=7, n_estimators=500, random_state=101, tree_method='gpu_hist')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T16:55:03.835835Z",
     "iopub.status.busy": "2024-08-29T16:55:03.835121Z",
     "iopub.status.idle": "2024-08-29T17:09:26.709385Z",
     "shell.execute_reply": "2024-08-29T17:09:26.708416Z",
     "shell.execute_reply.started": "2024-08-29T16:55:03.835787Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store accuracy scores for each classifier\n",
    "accuracy_scores = []\n",
    "\n",
    "# Iterate over each classifier and its name in the classifiers dictionary\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    y_pred = clf.predict(X_test_combined)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    print(\"For\", name)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    \n",
    "    # Compute the confusion matrix for the predictions\n",
    "    # 'lbl_enc.classes_' provides the class labels for the confusion matrix and classification report\n",
    "    labels = lbl_enc.classes_\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(classification_report(y_test, y_pred, target_names=labels))\n",
    "    \n",
    "    # Plot the confusion matrix using a heatmap\n",
    "    # Annotate each cell with the numeric value of the confusion matrix\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Greens', xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted')  # Label for x-axis\n",
    "    plt.ylabel('Actual')     # Label for y-axis\n",
    "    plt.title(f'Confusion Matrix for {name}')  # Title for the heatmap\n",
    "    plt.show()  # Display the heatmap\n",
    "    \n",
    "    # Append the accuracy score to the list\n",
    "    accuracy_scores.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T17:09:26.711032Z",
     "iopub.status.busy": "2024-08-29T17:09:26.710721Z",
     "iopub.status.idle": "2024-08-29T17:09:27.078399Z",
     "shell.execute_reply": "2024-08-29T17:09:27.077349Z",
     "shell.execute_reply.started": "2024-08-29T17:09:26.710998Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame to store classifier names and their corresponding accuracy scores\n",
    "accuracies_df = pd.DataFrame({'Classifier': classifiers.keys(), 'Accuracy': accuracy_scores}).sort_values('Accuracy', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "palette = dict(zip(accuracies_df['Classifier'], colors[:4]))\n",
    "\n",
    "# Create a bar plot to visualize the accuracy of each classifier\n",
    "sns.barplot(x='Classifier', y='Accuracy', data=accuracies_df, palette=palette)\n",
    "\n",
    "plt.title(\"Classifier Accuracy Comparison\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding: 20px; border-color: #419D78; border-radius: 10px; box-shadow: 0 2px 4px 0 rgba(0, 0, 0, 0.1); border: 2px solid #419D78;\">\n",
    "    <ul style=\"font-size: 18px; font-family: 'Arial'; line-height: 1.5em; \">\n",
    "        In this project, we evaluated four models designed to handle large datasets with numerous features: <strong>Bernoulli Naive Bayes</strong>, <strong>Decision Tree</strong>, <strong>Logistic Regression</strong>, and <strong>XGBoost (XGB)</strong>. <strong>XGBoost</strong> emerged as the top performer with an <strong>accuracy of 81%</strong>. The classification report showed that the Normal state was the easiest to distinguish with an F1 score of 93, followed by Anxiety and Bipolar with F1 scores of 85. Other states also performed well, with F1 scores above 70. Although the Confusion Matrix and WordCloud analysis revealed some overlap between depression and suicidal messages, XGBoost still outperformed the other models and demonstrated superior overall performance.\n",
    "    </ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5338273,
     "sourceId": 8870083,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
